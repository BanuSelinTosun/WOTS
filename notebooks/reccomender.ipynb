{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "#NLP\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read Files\n",
    "df_reviews=pd.read_csv('data/street_reviews.csv')\n",
    "df_reviews.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df_sample=pd.read_csv('data/data_seattle.csv')\n",
    "df_sample.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_reviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        stemmer_porter = SnowballStemmer('english')\n",
    "        analyzer = super(TfidfVectorizer, self).build_analyzer()\n",
    "        return lambda doc: [stemmer_porter.stem(word) for word in analyzer(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's keep these \n",
    "#u'bath', u'bathroom',u'bed', u'bedroom', u'bedrooms', u'beds',u'br', u'ba', u'appliances', u'appls',\n",
    "#       u'apps',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords_ = set(stopwords.words('english'))\n",
    "add_stopwords=[u'1st', u'2nd', u'3rd', u'alki', u'anne',\n",
    "       u'arbor', u'area', u'atlantic', u'baker',\n",
    "       u'ballard', u'bay', u'beach', u'beacon',\n",
    "       u'belltown', u'bitter',\n",
    "       u'blaine', u'blue', u'broadview', u'broadway', u'bryant',\n",
    "       u'business', u'capitol', u'cedar', u'central', u'city', u'columbia',\n",
    "       u'delridge', u'denny', u'district', u'downtown',\n",
    "       u'east', u'eastlake', u'fairmount', u'fauntleroy', u'floor',\n",
    "       u'floors', u'fremont', u'gatewood', u'genesee', u'georgetown',\n",
    "       u'green', u'greenwood', u'haller', u'harrison', u'heights', u'high',\n",
    "       u'highland', u'hill', u'hills', u'house', u'housing',\n",
    "       u'interbay', u'international', u'lake', u'laurelhurst', u'leschi',\n",
    "       u'licton', u'lower', u'madison', u'madrona', u'magnolia', u'mann',\n",
    "       u'market', u'meadowbrook', u'minor', u'montlake', u'mount',\n",
    "       u'neighborhood', u'north', u'northgate', u'olympic', u'park',\n",
    "       u'phinney', u'pike', u'pioneer', u'point', u'portage', u'queen',\n",
    "       u'rainier', u'ravenna', u'ridge', u'riverview', u'roxhill', u'sand',\n",
    "       u'seattleadmiral', u'seaview', u'seward', u'south', u'springs',\n",
    "       u'square', u'stevens', u'sunset', u'terrace', u'union',\n",
    "       u'university', u'victory', u'wallingford', u'wedgeview', u'west',\n",
    "       u'westlake', u'whittier', u'yesler']\n",
    "for word in add_stopwords:\n",
    "    stopwords_.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_abrv(text_):\n",
    "    return text_.replace('\\\\n','').replace(' ba ',' bathroom ').replace(' bdrm ', ' bedroom ')\\\n",
    "                .replace(' br ', ' bedroom ').replace( ' appls ', ' appliances ').replace(' appls ', ' appliances ')\\\n",
    "                .replace(' bdr ', ' bedroom ').replace(' flrs ', ' floors ').replace(' flr ', ' floor ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def post_tag_nouns_adj(text_):\n",
    "    return ' '.join([t[0] for t in pos_tag(text_.split())if t[1].startswith(('JJ','NN'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuations(text_):\n",
    "    punctuations_=set(string.punctuation)\n",
    "    return ''.join(word for word in text_ if word not in punctuations_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_digits(text_):\n",
    "    return ' '.join(s for s in text_.split() if not any(c.isdigit() for c in s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_text(text_list,post_tagged=False):\n",
    "    cleaned_text_list=[]\n",
    "    for i in range(len(text_list)):\n",
    "        review_fixed = fix_abrv(text_list[i])\n",
    "        review_no_punc = remove_punctuations(review_fixed)\n",
    "        if post_tagged==True:\n",
    "            cleaned_text_list.append(post_tag_nouns_adj(review_no_punc))\n",
    "        else:\n",
    "            cleaned_text_list.append(remove_digits(review_no_punc))\n",
    "    return cleaned_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def top_three_dictionary(text_list,label_list,posttagged = False, ngrammin=2,ngrammax=2, alt=False, alt_id='NULL'):\n",
    "   \n",
    "    ## check if it is alternative neighborhood\n",
    "    if alt == True:\n",
    "        alt_text = df_sample[df_sample['id']==alt_id]['remarks'].values\n",
    "        text_list = np.append(text_list,alt_text)\n",
    "        label_list = np.append(label_list,alt_id)\n",
    "    \n",
    "   \n",
    "    ## get cleaned textreview\n",
    "    textreview = clean_text(text_list,post_tagged=posttagged)\n",
    "\n",
    "    ## stemmed vectorizer\n",
    "    Stemmed_Vectorizer=StemmedTfidfVectorizer(stop_words=stopwords_,ngram_range=(ngrammin, ngrammin))\n",
    "    Stemmed_Vectors=Stemmed_Vectorizer.fit_transform(textreview)\n",
    "    Stemmed_Review_Vectors=Stemmed_Vectors.toarray()\n",
    "\n",
    "    ## find 3 most similar items \n",
    "    n=3 \n",
    "    similatiry_dict={}\n",
    "    for i in range(len(label_list)):\n",
    "        cos_sim = cosine_similarity(Stemmed_Review_Vectors[i:(i+1)], Stemmed_Review_Vectors)\n",
    "        order = list(cos_sim.argsort()[0][::-1][1:n])\n",
    "        top_three = label_list[order]\n",
    "        similatiry_dict[label_list[i]]=top_three.tolist()\n",
    "\n",
    "    \n",
    "    return similatiry_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neighborhood_dict=top_three_dictionary(df_reviews['reviews'].values,df_reviews['name'].values,posttagged = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minbed=5\n",
    "maxbed=4\n",
    "minbath=3\n",
    "maxbath=4\n",
    "prop_type='Residential'\n",
    "neighborhood='Ballard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def home_reccomender_dict(minbed,maxbed,minbath,maxbath,prop_type,neighborhood,alt=False, alt_id='NULL'):\n",
    "    reccomender_dictionary={}\n",
    "    minbed, maxbed = sorted([minbed,maxbed])\n",
    "    minbath, maxbath = sorted([minbath,maxbath])\n",
    "    \n",
    "    df_select= df_sample[(df_sample['bed']<=maxbed) & (df_sample['bed']>=minbed) &\n",
    "               (df_sample['bath']<=maxbath) & (df_sample['bed']>=minbath) &\n",
    "               (df_sample['prop_type']==prop_type)&\n",
    "               (df_sample['street_neighborhood']==neighborhood)][['id','remarks']]\n",
    "    \n",
    "    ## check if there is any match\n",
    "    \n",
    "    if df_select.shape[0]==0:\n",
    "        return 'Sorry, no match found. Please change your search options and try again :)'\n",
    "    \n",
    "    if df_select.shape[0]==1:\n",
    "        return df_select\n",
    "    \n",
    "    ## check if there are enough number of listings \n",
    "    elif df_select.shape[0]<=3:\n",
    "        for i in range(df_select.shape[0]):\n",
    "            reccomender_dictionary[df_select['id'].values[i]]=\\\n",
    "                                    np.setdiff1d(df_select['id'].values,df_select['id'].values[i])  \n",
    "    else:\n",
    "    \n",
    "        df_select.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        reccomender_dictionary = top_three_dictionary(df_select['remarks'].values,df_select['id'].values,\\\n",
    "                                                      alt=alt,alt_id=alt_id)\n",
    "    return reccomender_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def home_reccomender_part_i(reccomender_dictionary):\n",
    "    return reccomender_dictionary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def home_reccomender_part_ii(reccomender_dictionary,selected_home,neigborhood):\n",
    "    # check if there are more than 3 listings\n",
    "#    if len(reccomender_dictionary)<=3:\n",
    "#        return reccomender_dictionary\n",
    "    \n",
    "#    else: \n",
    "    result_dict={}\n",
    "\n",
    "    result_dict[neighborhood] = reccomender_dictionary[selected_home]\n",
    "\n",
    "    alt_neig_1, alt_neig_2 = neighborhood_dict[neighborhood]\n",
    "\n",
    "    result_dict[alt_neig_1] = home_reccomender_dict(minbed,maxbed,minbath,maxbath,prop_type,\\\n",
    "                                                      neighborhood=alt_neig_1,alt=True, alt_id=selected_home)\n",
    "    result_dict[alt_neig_1]=result_dict[alt_neig_1].get(selected_home,'sorry, no match found')\n",
    "\n",
    "    result_dict[alt_neig_2] = home_reccomender_dict(minbed,maxbed,minbath,maxbath,prop_type,\\\n",
    "                                                      neighborhood=alt_neig_2,alt=True, alt_id=selected_home)\n",
    "    result_dict[alt_neig_2]=result_dict[alt_neig_2].get(selected_home,'sorry, no match found')\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mydict = home_reccomender_dict(minbed,maxbed,minbath,maxbath,prop_type,neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "home_reccomender_part_i(mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "home_reccomender_part_ii(mydict,58614,'Ballard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stop here, tasks to do :\n",
    "# add selected home vs reccomended neighborhood home comparision\n",
    "# carry this to atom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def top_three_dictionary_old(text_list,label_list):\n",
    "    '''\n",
    "    input:\n",
    "    text_list: list of string\n",
    "    label_list: list of string\n",
    "    output:\n",
    "    dictionary of key = text label values: 3 similar labels\n",
    "    '''\n",
    "    #remove punctuations & numbers and keep only nouns and adjectives\n",
    "    punctuations_=set(string.punctuation)\n",
    "    textreview=[]\n",
    "    for i in range(len(text_list)):\n",
    "        #review_=' '.join([t[0] for t in pos_tag(text_list[i].split())if t[1].startswith(('JJ','NN'))])\\\n",
    "        review_=text_list[i].replace('\\\\n','').replace(' ba ',' bathroom ').replace(' bdrm ', ' bedroom ')\\\n",
    "        .replace(' br ', ' bedroom ').replace( ' appls ', ' appliances ').replace(' appls ', ' appliances ')\\\n",
    "        .replace(' bdr ', ' bedroom ').replace(' flrs ', ' floors ').replace(' flr ', ' floor ')\n",
    "        \n",
    "        review = ''.join(word for word in review_ if word not in punctuations_)\n",
    "        textreview.append(' '.join(s for s in review.split() if not any(c.isdigit() for c in s)))\n",
    "    \n",
    "    ## stemmed vectorizer\n",
    "    nmin=2\n",
    "    nmax=2\n",
    "    Stemmed_Vectorizer=StemmedTfidfVectorizer(stop_words=stopwords_,ngram_range=(nmin, nmax))\n",
    "    Stemmed_Vectors=Stemmed_Vectorizer.fit_transform(textreview)\n",
    "    Stemmed_Review_Vectors=Stemmed_Vectors.toarray()\n",
    "    \n",
    "    ## 3 most similar items \n",
    "    n=3 \n",
    "    similatiry_dict={}\n",
    "    for i in range(len(label_list)):\n",
    "        cos_sim = cosine_similarity(Stemmed_Review_Vectors[i:(i+1)], Stemmed_Review_Vectors)\n",
    "        order = list(cos_sim.argsort()[0][::-1][1:n])\n",
    "        top_three = label_list[order]\n",
    "        similatiry_dict[label_list[i]]=top_three.values.tolist()\n",
    "    return similatiry_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## check neighborhoods based on reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "similarity_dict=top_three_dictionary(df_reviews['reviews'],df_reviews['name'],posttagged = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#similarity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find homes 1-2 bedroom 1-2 bathroom in Ballard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minbed=1\n",
    "maxbed=2\n",
    "minbath=1\n",
    "maxbath=2\n",
    "prop_type='Residential'\n",
    "neighborhood='Ballard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_select= df_sample[(df_sample['bed']<=maxbed) & (df_sample['bed']>=minbed) &\n",
    "               (df_sample['bath']<=maxbath) & (df_sample['bed']>=minbath) &\n",
    "               (df_sample['prop_type']==prop_type)&\n",
    "               (df_sample['street_neighborhood']==neighborhood)][['id','remarks']]\n",
    "df_select.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listing_similarity_dict=top_three_dictionary(df_select['remarks'],df_select['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listing_similarity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_sample[df_sample['id'].isin([5558,240833, 264174])][['id','bed','bath','sqft','address','latitude','longitude','price','selling_price','mls_prop_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check neighborhoods based on listing descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_list = np.unique(df_sample.street_neighborhood.values)\n",
    "label_list = map(str, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remarks_list = []\n",
    "for label in label_list:\n",
    "    remarks_list.append(''.join(\n",
    "            map(str, df_sample[df_sample['street_neighborhood']==label]['remarks'].values)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_remarks = pd.DataFrame(\n",
    "    {'label': label_list,\n",
    "     'remarks': remarks_list\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_remarks['label']=df_remarks['label'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_remarks['remarks']=df_remarks['remarks'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "similarity_dict_list=top_three_dictionary(df_remarks['remarks'],df_remarks['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "similarity_dict_list['Atlantic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## did some search below this - comparable homes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neighbourhood_list=np.unique(df_sample.street_neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample['selling_date']=pd.to_datetime(df_sample['selling_date'])\n",
    "df_sample['year_built']=df_sample['year_built'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_results=pd.DataFrame()\n",
    "for n in neighbourhood_list:\n",
    "    df=df_sample[(df_sample['street_neighborhood']==n) &( df_sample['mls_status']=='Sold')]\n",
    "    df=df.reset_index()\n",
    "    df.drop('index',axis=1,inplace=True)\n",
    "    for i in range(df.shape[0]):\n",
    "        df_filtered = df[(df['bed']==df.iloc[i]['bed'])\\\n",
    "                & (df['bath']==df.iloc[i]['bath'])\\\n",
    "                & (df['year_built'].isin(range(df.iloc[i]['year_built']-5,df.iloc[i]['year_built']+6)))\\\n",
    "                & (df['selling_date'].dt.year.isin(range(df.iloc[i]['selling_date'].year-1,df.iloc[i]['selling_date'].year+2)))         \n",
    "                & (df['mls_prop_type']==df.iloc[i]['mls_prop_type'])]\n",
    "        if len(df_filtered)>1:\n",
    "            df_results=pd.concat([df_results,df_filtered])\n",
    "            df_results=df_results.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_results.shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
